

A B C Z
2 4 5 22
1 2 6 18
3 5 2 21
3 1 4 21
z = 4A + B + 2C 이게 선형회귀다 마



Feature Engineering 
주어진 데이터의 피처를 적절히 활용하여 새로운 피처를 제작함

시계열은 과거의 값이 현재의 값을 예측하는데 도움이 됨 
와 이래서 Auto Correlation을 활용한 거구만이제 이해가 됨
심지어 2개를 활용할 수 있음
Time 이전 Value(2) 이전 Value target
2010-11-13                     130
2010-11-20            130        222
2010-11-27 130       2222     166


그렇다면 비어있는 값은 어떻게 해야할까요??
하지만 인공지능을 만들때는 빈공간이 이으면 안되느데!!!그럼 중간값으로 채워?? 음 일단 공란있는건 쓰지말자 라고 결론을 내릴수도!

데이터 정제의 유형 - 정답은 없음
1. imputation 중복제거
 평균값(Average), 중간값(Median), 최빈값(Mode)
2. Handling Outlier 아웃라이어
3. Binning 비닝
10대 20대 30대 나이를 클래스 묶어주는 느낌, 비닝을 어떻게 하느냥 ㅔ
4. log Transform
값이 큰쪽으로 쏠려 있는 걸 정규화 시켜줌, Outlier의 영향을 줄여줌
5. One-Hot Encoding 
범주형 데이터를 컬렴으로 올림 
6. Group Operations
데이터를 적절히 합쳐(aggregation) 더 의미있는 단위로 만듦 행을 합칠 수 있다.
7. Feature Split
데이터를 적절히 나누어 더 의미있는 단위로 만듦 , 시, 분, 오전, 오후 등
8. Scaling
월급, 나이 단위는 월급크지만 가중치는 나이가 높을 수 있음, 그래ㅓ 이를 스케일링 함 (MInMaxScalser)
9. Lagging
시게열 데이터 개수를 늘리기 위해, 과거 데이터와 현재의 데이터를 비교하는데 활용

추천 (Recommendation)
기본적인 추천 방법 : 비슷함을 찾는거임
A : B시청
이떄
1. 영화 B와 비슷한 영화는?
2. A와 비슷한 사용자는?

추천의 두 가지 접근 (아마존 추천 매출물 35%, 유튜브 80%)
1. 컨텐츠 기반 필터링 (COntents base )
1.1  장점
다른 사용데이터 필요 ㄴㄴ
1.2  단점
영화의 특징을 파악하기 힘들어
사람들이 좋아하는 특징을 켓치하고 정형화 하기 힘들어, 즉 특성을 파악하기 힘듦 

평점 예측 결과를 제공
- 회귀

 정밀도 
 1 0.(1/1)   25
 0.5(1/2)
0.6 (2/3)
 MAP - (맞혔둰경우만 평균)

 AEC 


추천 항목을 나열

2. 협력 필터링 (Collaborative Filtering)


분류 결과의 평가 지표
우리 모델이 얼마나 분류 결과를 잘 예측 하였는가?

Accuracy : 정확도(옳은 분류 갯수 / 전체 분류 갯수)

Precision (정밀도) : 모델이 yes라고 분류했을 떄 정말 yes일 경우
 True Postive / (True Postive + False Postive )    

Recall(재현율) : 전체 yes 경우에서 얼마나 옳게 yes라고 한경우 
True Postive / True Postve + Faslse Negative  

정밀도가 높다 : 우리 모델이 yes라고 하면 정말로 yes일 확률이 높다
               yes를 잘 이야기 하지 않을려고 한다 -> yes를 이야기 하지 않으려 한다.

재현율이 높다 : 정답이 yes인 항목을 잘찾아낸다
              비교적  

precison 1, Recall 0
이건 하나도 못잡아낸거임..

Threshold : 분류 모델이 분류하는 방법, 분류의 확률 세기 // threshold가 높으면 yes라고 말할 경우가 더 줄어들고, 낮추면 더 쉽게 yes를 말함 



TPR과 FPR


ROC CUrve - Threshold가 낮아지면 yes라고 말하는경우가 많아지고 ,, 그럼 덜 보수적으로 바뀌겠지!

True Postive rate = y축 (TPR)
fasle Postive Rate = x축 (FPR)

여전히 ROC curve 만으로는 모델의 성능을 결정할 수없어/.

왜?? threshold가 없잖아

그렇가면 threshold는?? 

AUC (Area Under the Curve)
AUC가 크면, 1이 되는거고,


000000 xxxxxxxx
xxxxxxxxxxxxxxxxxxxx
0xxxxxxxxxxxxxxxx
000xxxxxxxx

000000xxxxx
TPR : 1,  FOPR :  0 <<<threshold가 가장 이상적일 경우

xxxxx0xx0x
TPR 0, FPR = 0.43

최악으로 설계ㅚㄴ 경우.. 랜덤으로 
TPR 0.2, FPR 0,14 이런 경우

0.5 <= AUC <= 1







logistic 모델은 깡통

Test and Score 임마가 학습 모델

데이터 ......... 기술적인 용어나, 모델링이날, 평가지표에 대한 적절한, 값의 범위는 업에 대한 이해도가 있으신 분들
즉 정확도가 절대 절대적인 지표가 아니다, 평가지표를 잘 활용하자!!


Restaurant Dataset

1. 협업 필터링
- 사용자 성향의 비슷함을 확인하고 추천하는 시스템 

2. 컨텐츠 기반 필터링

지도학습,, 회귀, 분류, 추천

범주를 나누는거에선 

## 추천결과를 평가 하는방법 (표현 방법이 다름)
1. 평점 - 사람이 어떻게 평가했는지, 인공지능이 예측했던 점수를 비교
 MAE, RMSE
2. 평점이 예측하는것이 아니라 나열 하는 것 -
MAP, MAR, NDCG

평가를 왜 이렇게 하는지 이해하는것이 중요해, 그래서 왜 이 지표가 필요한가, 좋냐 나쁘냐를 판달 할 수 있는지 중요함

## 평점 예측 결과에 대한 평가 
추천 알고리즘 precision, recall
아 그리고 추천 알고리즘은 순서가 굉장히 중요하다

MEAN AvERAGE PRECISION
- 순서를 맞춰줌, 순서를 맞출수록 더 높은 점수를 준다 

DCG (Discounted Cumulated Gain)
 - 평점의 스케일에 따라 영향을 많이 받음..
 - Normalization이 필수이다 // 뭐롤 나누눌까 ?? 현재값 / 이상적인 값


 추천 알고리즘의 가장 핵심은
 누가 가장 유사한가

 어떤게 이거랑 가장 비슷한가임

 추천 시스템 만들떄 고민되느게
 이 데이터로 가능한가?? 

 유저가 명확하지 않을때.. 로그인을 하지 않은 회원한테 추천하고 싶을 땐 어떻게 할까나

 ## 협력 필터링 (Collaboative Filtering)
 취향이 ㅣ슷한 사용자의 소비 패턴을 기반으로 추천함

1. 장르를 기준으로 추천 / 평점보단 데이터가 많음 // 근데 지나치게 심플하게 생각하느 경우가 발생 

2. 군집화 // 비슷한 데이터를 묶어보자

 - 데이터의 경향이 보여, 데이터를 추상적으로 이해 하는데 도움이 됨

 - K-MEANS Clustrering
   1. 임의로 점 K개를 찍는다
   2. 모든 데이터에 대하여 X를 기준으로 그룹화 한다.

   3. X를 옮긴다.
   4. 한 번더 X를 기준으로 그룹화
   5. 또 X를 각 그룹의 중심으로 이동한다

   # 언제까지 이걸 반복할까 // 이 중심점이 더 이상 움직이지 않을때까지 ....

   kmenas 를 활용하기 위해선 제일먼저 K를 결정해줘야함.. 적절한 K가 몇개인가를 구하는 방법도 있지요

 K를 1일떄도 해보고 2일 때도 해보고 , 3일때도 해보고 해보면서, 적절한 K를 찾아보는거임

 Kmeans는 비지도 학습임 .. 학습데이터에 레이블이 없어도 된다 

 협력 필터링 + K-means : 그룹을 기준으로
아키텍쳐 분석
1. Data Kmeans (잘 클러스터링 해줘야 정화도가 높아짐) - 2. 데이터 마징(평정데이터와 합쳐) 3. 데이터 샘플링(학습데이터와 테스트 데이터를 나눠줌) 4. BIMS 모델에, 전처리한 데이터를 학습시키미  5.Prediction 함수를 통해서 데이터를 

 - 보통 Test and Score 함수가 k-ford 즉 데이터 나누는거, 모델 학습까지 담당했던거에 비해 불편하지


 /////////////////

 데이터 모델 

언제 선형모델이 아니라고 판단할 수 있을까 

선형관계가 아니고 비선형일 경우 디시전 트리가 좀 더 복잡한 경계면을 잘 그음 ㅎㅎ 

디지전 트리가 원래 복잡한게 아닌데 파라미터를 높요서 ... 오버피팅 시킬 수가 있음
그러므로 적절한 복잡도가 요구됨

모델의 복잡도를 높이면.. 학습한 거에선 높은 정확도를 나타낸다..

- 편형된 모델의 결과 불균형 데이터 

예시 : 백인 Popular, 데이터가 편향되어 있으면 선을 못그음 

불균형 데이터의 해결 

1.  Undersampling majority
 - Major Class 원소를 무작위로 소수만 선택 
 - 정보를 잃는 꼴이됨..  / 아까워
 
2. Oversampling minority
 - 소수의 집단에 대해서 더 샘플링 하는건데 / 조금 어려움 // 서른건을 백건으로 늘려!
 - SMOTE = Synthetic Minority Over-Sampling Techinque // 개별의 아이템을 높이는것보단,, 

임벨런스 되어 있는 데이터 셋 // 불균형 데이터를 해결하기 / 정보를 크리티컬 하는 것 
