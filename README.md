 # 1. 데이터 분석 피처 엔지니어링



1. 결측값 처리 <- 
2. 이상값 처리 <- 기업 전기사용량(삼성전자보다 어떤 던킨도너츠 전기사용량...<*---- 이런) 기업의 매출액 프로젝트
3. 머신러닝 모델을 활용해서 예측  < -----



데이터 분석 파이프라인(pipeline)

그런데 우리는 왜 데이터를 분석하는 것일까? 기본적으로는 데이터 분석은 의사결정의 근거를 파악하기 위해 수행한다고 볼 수 있다. 
예를 들어 제조 기업 경우 과거 판매 데이터와 경제 지표 등의 데이터를 수집해서 가공해 분석하고 미래 수요를 예측해 생산량과 원자재 구매에 대한 의사결정을 내릴 수 있을 것이다. 
그리고, 이러한 분석 절차는 일회성에 그치는 것이 아니라 월별, 분기별, 연도별 심지어 준실시간(near-real time)으로 분석할 수도 있다. 
제조 업체의 예시와 같이 데이터의 수집, 전처리, 분석, 예측과 같은 일련의 과정을 데이터분석 파이프라인이라 한다.

데이터, 정형(structured) 데이터와 비정형(un-structured) 데이터

데이터 사이언스 이름 자체에서 알 수 있듯이 데이터 사이언스는 데이터와 관련된 과학을 연구하는 분야이다. 그렇다면 데이터(data)란 무엇일까? 한 기관에서 발행한 통계 용어집(OECD Glossary of Statistical Terms, 2008)에 보면 데이터를 보통 수치(numeric) 형태의 관찰값(observation)이라고 정의하고 있다. 일반적으로는 꼭 수치 형식일 필요는 없을 것이며 그림, 도표 등도 모두 데이터라고 봐도 무방할 것이다.

일반적으로 데이터를 분석하기 위해서는 데이터를 분석하기 쉽도록 엑셀의 테이블과 같은 형식으로 정리하는 과정이 필요하다. 이렇게 테이블 형식으로 정리된 데이터를 정형 데이터라고 하며, 반대로 특정 형식으로 정리하기 전에 정형화된 구조를 갖고 있지 않은 데이터를 비정형 데이터라 한다.

정형 데이터는 우리가 많이 사용하는 엑셀 테이블이나 관계형 데이터베이스(RDBMS)의 테이블을 생각하면 쉽게 이해할 수 있다. 반면, 특정 구조를 갖고 있지 않은 문서들이나 사진들, 기계가 생산해 낸 로그(log) 파일, 소셜미디어에 올라오는 글과 같은 데이터가 비정형 데이터의 예시이다.

# 2. 피처(feature)

엑셀 테이블을 분석할 때에는 행(column)과 열(row)을 기준으로 분석하게 된다. 데이터 사이언스 관련된 책이나 글을 보다 보면 행과 열이라는 용어도 사용하지만 

 피처(feature), 속성(attribute), 관찰값(observation), 샘플(sample), 변수(variable) 등과 같은 용어들을 자주 접하게 된다. 이러한 용어들을 엑셀의 테이블을 예로 들어 살펴보자.

 엑셀을 분석할 때 주로 사용하는 방법 중 하나가 각 열에 필터(filter)를 적용하는 것이다. 이는 각 열이 다른 열과는 다르게 데이터 테이블의 고유한 특성을 갖고 있기에 특정 열을 기준으로 다른 값들이 어떠한 값을 갖는지 쉽게 알 수 있어 자주 사용하게 된다.

 이와 같이 열 하나 하나가 데이터 테이블의 특징을 나타내므로 피처 또는 특성이라고 한다. 그리고 테이블의 속성을 나타내는 요소의 의미로 속성(attribute)이라고도 부른다. 실험 환경에서는 데이터의 열 중 결괏값에 영향을 주는 변수들을 독립변수(independent variable)라 하며, 독립변수들의 영향으로 나온 결과값을 목적변수(target variable)라고 한다. 그 밖에 엑셀에서와 같이 필드(field)라는 용어도 사용된다.

자, 이제 데이터 테이블의 가로 방향인 행을 살펴보자. 데이터 테이블은 여러 행들이 모여 하나의 테이블을 이루게 되는데 여기서 행은 데이터를 수집할 때 하나하나 수집한 값이기에 이를 관찰값(observation) 혹은 레코드(record), 인스턴스(instance)라고도 하며, 전체 데이터에서 일부 혹은 하나만 선택한 값이라는 의미로 샘플(sample)이라는 용어도 사용한다.

- 데이터 탐색(Exploratory data analysis, EDA)

데이터 탐색은 데이터 테이블의 기초 통곗값, 결측값, 피처들 간의 관계를 확인하고 데이터의 범위, 분포 등을 히스토그램과 같은 다양한 그래프를 통해 시각화(visualization)해서 데이터를 이해하고 분석할 방향을 설정해보는 과정이라고 할 수 있다. 이 과정에서 파악한 정보를 바탕으로 분석을 위한 데이터 전처리 과정을 거치게 된다.

- 데이터 전처리(preprocessing)

실제 데이터를 수집하고 분석하다 보면 우리가 일상에서 접하던 엑셀 데이터와 같이 깔끔한 테이블 형식으로 정리된 경우는 드물다. 데이터 분석에서 널리 사용되는 말 중 하나가 “Garbage in, Garbage out”으로 어떠한 데이터를 입력하느냐에 따라 찾고자 하는 값의 품질이 좌우된다. 따라서 분석에 사용하기 적당한 형태로 데이터를 준비하는 과정이 필요하며 이를 데이터 전처리라고 한다. 전처리 과정은 데이터의 빈값을 처리하거나 적절하지 않은 값을 걸러내는 클리닝(cleaning), 데이터 테이블 전체를 분석하기 어려운 경우 적절하게 샘플 데이터를 선택하는 인스턴스 선택(instance selection), 피처들의 범위를 0~1, -1~1 혹은 정규분포로 변형해 피처들 간의 영향력을 균등하게 해주거나 처리 속도를 빠르게 해주는 정규화(normalization)와 표준화(standardization) 작업 등을 일반적으로 데이터 전처리라 한다. 각 과정들은 추후 예제와 함께 좀 더 자세히 설명할 것이다.

- 피처 엔지니어링(feature engineering)

위에서는 데이터의 구조에 따라 정형 데이터와 비정형 데이터로 분류해 보았다. 그 밖에도 데이터 값의 형식에 따라 수치형(numeric) 데이터, 범주형(categorical) 데이터로 나눌 수 있다. 
또, 수치형 데이터는 이산형(discrete)과 연속형(continous)으로 구분할 수 있으며, 범주형은 명목형(nominal)과 순서형(ordinal)으로 구분된다. 
이러한 다양한 데이터를 컴퓨터가 연산하기 쉽고 찾고자 하는 목적을 잘 반영할 수 있도록 도메인 지식을 토대로 피처를 새로 만들거나 변형하는 작업이 필요하다. 
데이터 전처리와 피처 엔지니어링을 어떻게 하냐에 따라 모델의 성능이 달라지기에 실제 업무에서는 이 두 가지 영역에 가장 많은 노력을 기울이게 된다.

- 모델링(modeling)

지금까지의 데이터 준비과정을 거처 피처와 목적변수 사이의 관계를 찾는 과정이 필요하다. 
이 과정에서 문제에 적합한 다양한 알고리즘이 사용되게 되며 이러한 수학적 모델을 찾는 과정을 모델링이라 한다. 이 과정을 거쳐 나온 결과물을 모델이라 할 수 있다.

- 예측(prediction)

지금까지 데이터를 준비해서 모델을 만든 이유는 새로운 조건이 주어졌을 때 어떠한 결과가 나오는지를 알기 위함이다. 우리가 만든 모델에 피처에 값들을 넣어주게 되면 찾고자 하는 목적 변수의 값을 얻을 수 있으며 이 과정을 예측이라 한다.

- 성능평가(evaluation)

데이터 사이언스에서 풀고자 하는 문제는 크게 회귀(regression)와 분류(classification)로 구분할 수 있다. 회귀의 경우 찾고자 하는 값이 수치형으로 표시되며 실제값과 예측값의 차이로 성능을 평가할 수 있다. 이에 반해 분류형 문제는 데이터의 범주를 예측하는 문제로, 실제 분류를 얼마나 잘 했는지를 혼동행렬(confusion matrix)를 기본으로 ROC, AUC등의 지표로 평가하게 된다. 각각에 대해서는 추후 더 설명하도록 한다.

이 밖에도 책이나 실무를 통해ETL(Extract, Transform and Load), 먼징(munging), 랭글링(wrangling) 등 다양한 용어를 만나게 될 것이다. 하지만 위에서 설명한 기본적인 개념과 크게 다르지 않으며 전처리나 피처 엔지니어링 등은 겹치는 부분도 많아 명확하게 구분하기 힘든 부분도 있다. 앞으로는 위에서 설명한 과정 하나하나에 대해 조금 더 상세하게 살펴볼 것이다.


데이터 탐색

데이터 분석에 있어 가장 중요한 부분은 `데이터 전처리`와 `피처 엔지니어링`이라고 할 수 있다. EDA 과정으로 데이터를 정확하게 이해하고 피처 각각의 특징에 맞도록 적절하게 전처리 및 피처 엔지니어링을 진행한다면 우수한 성능을 얻을 수 있을 것이다. 

 또 컴퓨터는 문자로 된 데이터를 계산할 수 없기 때문에 적당한 형태의 숫자로 변환해주는 과정도 반드시 필요하다.


 데이터를 확인하면 변수들을 어떻게 처리해야할지 아이디어를 얻을 수 있을 것이다. 또 데이터가 범주형(categorical)인지 수치형(numerical)인지, 범주형이라면 순서형(ordinal)인지 명목형(nominal)인지, 수치형이라면 연속형(continuous)인지 이산형(discrete)인지도 확인할 수 있다. 이 과정은 추후 피처 엔지니어링에서 변수를 어떻게 처리할지에 대한 중요한 정보를 제공한다.


다음은 수치형 데이터를 갖고 있는 변수들의 기초 통곗값을 확인한 결과다. age 변수를 보면 희생자가 0.17세부터 80세까지 있었다는 것을 알 수 있다. 또 sibsp(siblings and spouse, 동승한 형제자매와 배우자 수)와 parch(parent and children)을 통해 많은 가족이 함께 승선한 경우도 있었다는 것을 알 수 있다. 하지만, 지금까지의 정보만으로 실제 데이터 분포나 이상값(outlier)이 있는지 확인하기 어렵다.


데이터 시각화

가장 먼저 데이터 전체를 히스토그램으로 표시해 봤다. 하지만 원칙적으로는 막대그래프는 범주형 데이터를 표시하는 데 유용하며 히스토그램은 순서형 데이터를 표시하는데 유용하다는 것을 이해하고 사용해야 한다.

예를 들어, 타이타닉 데이터셋의 목적변수인 survived 변수의 경우 0(사망), 1(생존)으로 표시되는데 이때 0과 1은 숫자의 크기가 의미있는 것이 아니라 범주를 나누기에 막대그래프로 표현하는 것이 올바른 방식이다. 반면 age의 경우 1부터 숫자가 증가함에 따라 나이가 많아진다는 의미를 갖기 때문에 히스토그램으로 표현하는게 올바른 표현 방식이며, 이때 x축의 구간 개수를 조절해가며 데이터의 형태를 확인할 수 있다.

편의를 위해 히스토그램으로 표현한 그래프를 해석해 보면 데이터의 분포도 쉽게 살펴볼 수 있는데 pclass를 보면 대다수의 승객들이 3등급 객실을 이용한 것을 확인할 수 있다.

Survived 변수의 분포를 보면 사망자(0)가 생존자(1) 보다 많다는 사실도 알 수 있다. age 변수의 경우 (왼쪽으로 치우친) 정규분포의 형태를 띄며 대부분 20-30대 승객이 많았던 것을 알 수 있다.

sibsp와 parch에서는 대부분의 승객 1-2명이 이용했으며 8명 이상의 가족과 여행한 경우도 있다는 점을 짐작할 수 있다. fare 변수를 통해서 대부분 요금이 200(파운드 혹은 달러) 미만이었다는 것을 확인할 수 있다.

데이터셋이 이미 어느 정도 정제됐기 때문에 모든 변수에서 이상값이 나타나지는 않는 것으로 보인다. 만약 이상값을 갖는 경우 그래프 범위가 끝쪽으로 길게 늘어나고 맨 끝 데이터가 일부 표시되는 형태로 나타난다. 이를 통해 이상치가 있는지를 확인할 수 있다.

예를 들어, age 변수에 200살이 있었다면 0~80까지 데이터가 존재하다가 중간 데이터는 없고 200세에 데이터가 존재하는 경우다. 이는 현실적으로 잘못된 데이터일 확률이 많다.

하지만 모두 그런 것은 아니다. 만약 소득(연봉)이라는 변수에 1000억이라는 데이터가 있었다면 이는 잘못됐다고 할 수 있을까? 고민해볼 문제다. 이 부분도 피처 엔지니어링 부분에서 좀 더 다뤄볼 예정이다.


다음으로 수치형 데이터를 갖고 있는 상관관계를 피어슨 상관계수(person correlation coefficient)와 히트맵(heat map)으로 확인해보자.

피어슨 상관관계는 한 변수가 증가할 때 다른 변수도 증가하면 계수가 + 값을 갖으며 1인 경우 똑같은 비율로 증가한다는 의미다. – 값의 경우 반대로 해석하면 되고 0인 경우 변수 사이에 상관관계가 없다고 이해하면 된다.

우선 목적변수 survived와 어떤 변수가 상관관계가 높은지 살펴보면 양의 상관계수가 0.244265로 fare와 가장 큰 양의 상관관계를 갖는 것을 알 수 있으며 pclass와 -0.312469의 가장 큰 음의 상관관계를 갖는 것을 알 수 있다.

다시 말하면 높은 요금(fare)을 지불하고 좋은 등급(pclass)에 탑승한 승객이 생존(survived)할 확률이 높았다고 해석해 볼 수 있다. 안타까운 분석 결과이지만 너무 실망할 필요는 없다. 지금 분석한 데이터셋은 피처 전처리와 엔지니어링을 거치지 않은 데이터며, 모든 변수를 처리 후 분석하면 이보다는 희망적인 결과를 볼 수 있을 것이다.

상관관계도 위에서와 마찬가지로 숫자만으로 표현된 경우 눈에 잘 들어오지 않는다. 따라서 이를 히트맵으로 표현해보면 흰색과 검정색 영역을 구성하는 상관관계가 높은 변수들을 보다 쉽게 파악할 수 있다.


지금까지 공개 데이터셋을 활용해 데이터를 탐색하는 과정을 살펴봤다. 여기서 모두 다루지 못했지만 데이터를 사분위를 활용해 `중간값과 사분위`, `이상값`을 한번에 표시할 수 있는 `상자 그래프(box plot),` 두 변수 사이에 데이터 분포를 확인하기 `쉬운 산점도(scatter plot)` 등도 데이터 탐색에 매우 유용한 그래프다.

데이터 탐색 과정은 데이터를 이해하고 전처리 및 피처 엔지니어링을 진행하기 위해 진행하지만 실제 전처리 및 피처 엔지니어링을 진행한 후에도 반복적으로 데이터를 확인하기 위한 목적으로 진행한다.

또 시각화는 모델 성능을 평가하는 과정과 결과를 전달하는 과정에서도 사용되는 부분이다. 그래프를 표현하고자 하는 대로 표현할 수 있는 능력을 기르는 것도 매우 중요하다.

다음 시간에는 오늘 분석한 EDA 결과를 활용해 실제 데이터 피처 유형에 맞게 피처 엔지니어링을 진행하는 방법에 대해 다뤄 본다.



-출처 : 박정현 칼럼니스트는 서울대 EPM연구원(공학전문대학원 엔지니어링 프로젝트 매니지먼트 기사